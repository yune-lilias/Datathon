{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from torch_geometric.utils import negative_sampling\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.utils import train_test_split_edges\n",
    "from torch_geometric.data import Data\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc2vec_model = Doc2Vec.load(\"test_doc2vec.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_feature_array = []\n",
    "\n",
    "for i in range(len(doc2vec_model.docvecs)):\n",
    "    word_feature_array.append(doc2vec_model.docvecs[i])\n",
    "\n",
    "word_feature_array = np.array(word_feature_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>page_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  page_type\n",
       "0   0          1\n",
       "1   1          2\n",
       "2   2          3\n",
       "3   3          2\n",
       "4   4          4"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_type = pd.read_csv(\"./datasets/Training/node_classification.csv\")\n",
    "node_type_onehot = np.zeros([len(node_type), 4])\n",
    "for i in range(len(node_type)):\n",
    "    node_type_onehot[i][node_type.iloc[i][1]-1] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_feature_array = np.concatenate((word_feature_array, node_type_onehot), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge = pd.read_csv(\"./datasets/Training/training_graph.csv\")\n",
    "edge = edge.to_numpy().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = Data(x=torch.tensor(all_feature_array, dtype=torch.float32),\n",
    "    edge_index=torch.tensor(edge, dtype=torch.long), edge_attr=None)\n",
    "\n",
    "all_data.num_nodes = len(all_feature_array)\n",
    "all_data.num_features = len(all_feature_array[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_data = train_test_split_edges(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = GCNConv(data.num_features, 128)\n",
    "        self.conv2 = GCNConv(128, 64)\n",
    "\n",
    "    def encode(self):\n",
    "        x = self.conv1(data.x, data.train_pos_edge_index)\n",
    "        x = x.relu()\n",
    "        return self.conv2(x, data.train_pos_edge_index)\n",
    "\n",
    "    def decode(self, z, pos_edge_index, neg_edge_index):\n",
    "        edge_index = torch.cat([pos_edge_index, neg_edge_index], dim=-1)\n",
    "        logits = (z[edge_index[0]] * z[edge_index[1]]).sum(dim=-1)\n",
    "        return logits\n",
    "\n",
    "    def decode_all(self, z):\n",
    "        prob_adj = z @ z.t()\n",
    "        return (prob_adj > 0).nonzero(as_tuple=False).t()\n",
    "\n",
    "    def edgepred(self,z,te):\n",
    "        prob_adj = z @ z.t()\n",
    "        for k in range(len(te)):\n",
    "            probability = prob_adj[te[k][0]][te[k][1]]\n",
    "            probability = probability.detach().numpy()\n",
    "            te[k].append(probability)\n",
    "        \n",
    "        return te\n",
    "    \n",
    "    def pred_one_edge(self, z, new_node, top_k = 5, remove_negative = True):\n",
    "        prob_adj = z @ z.t()\n",
    "        rank_list = np.zeros(data.num_nodes)\n",
    "        for k in range(data.num_nodes):\n",
    "            if k == new_node:\n",
    "                rank_list[k] = -np.inf\n",
    "            else:\n",
    "                probability = prob_adj[new_node][k]\n",
    "                probability = probability.detach().numpy()\n",
    "                rank_list[k] = probability\n",
    "\n",
    "        index_list = rank_list.argsort()\n",
    "        top_k_index = index_list[-1:-top_k-1:-1]\n",
    "        top_k_score = rank_list[top_k_index]\n",
    "\n",
    "        if remove_negative:\n",
    "            for neg_point, inde in enumerate(top_k_score):\n",
    "                if inde < 0:\n",
    "                    break\n",
    "            top_k_index = top_k_index[:neg_point]\n",
    "            top_k_score = top_k_score[:neg_point]\n",
    "\n",
    "        return top_k_index, top_k_score\n",
    "\n",
    "\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = 'cpu'\n",
    "model, data = Net().to(device), data.to(device)\n",
    "model = model.float()\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=0.01)\n",
    "\n",
    "\n",
    "def get_link_labels(pos_edge_index, neg_edge_index):\n",
    "    E = pos_edge_index.size(1) + neg_edge_index.size(1)\n",
    "    link_labels = torch.zeros(E, dtype=torch.float, device=device)\n",
    "    link_labels[:pos_edge_index.size(1)] = 1.\n",
    "    return link_labels\n",
    "\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "    neg_edge_index = negative_sampling(\n",
    "        edge_index=data.train_pos_edge_index, num_nodes=data.num_nodes,\n",
    "        num_neg_samples=data.train_pos_edge_index.size(1),\n",
    "        force_undirected=True,\n",
    "    )\n",
    "    optimizer.zero_grad()\n",
    "    z = model.encode()\n",
    "    link_logits = model.decode(z, data.train_pos_edge_index, neg_edge_index)\n",
    "    link_labels = get_link_labels(data.train_pos_edge_index, neg_edge_index)\n",
    "    loss = F.binary_cross_entropy_with_logits(link_logits, link_labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def test():\n",
    "    model.eval()\n",
    "    perfs = []\n",
    "    for prefix in [\"val\", \"test\"]:\n",
    "        pos_edge_index = data[f'{prefix}_pos_edge_index']\n",
    "        neg_edge_index = data[f'{prefix}_neg_edge_index']\n",
    "        z = model.encode()\n",
    "        link_logits = model.decode(z, pos_edge_index, neg_edge_index)\n",
    "        link_probs = link_logits.sigmoid()\n",
    "        link_labels = get_link_labels(pos_edge_index, neg_edge_index)\n",
    "        perfs.append(roc_auc_score(link_labels.cpu(), link_probs.cpu()))\n",
    "    return perfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.4684, Val: 0.9271, Test: 0.9289\n",
      "Epoch: 002, Loss: 0.4653, Val: 0.9287, Test: 0.9304\n",
      "Epoch: 003, Loss: 0.4658, Val: 0.9303, Test: 0.9320\n",
      "Epoch: 004, Loss: 0.4649, Val: 0.9313, Test: 0.9330\n",
      "Epoch: 005, Loss: 0.4625, Val: 0.9320, Test: 0.9336\n",
      "Epoch: 006, Loss: 0.4617, Val: 0.9331, Test: 0.9345\n",
      "Epoch: 007, Loss: 0.4624, Val: 0.9345, Test: 0.9357\n",
      "Epoch: 008, Loss: 0.4625, Val: 0.9356, Test: 0.9369\n",
      "Epoch: 009, Loss: 0.4590, Val: 0.9361, Test: 0.9375\n",
      "Epoch: 010, Loss: 0.4585, Val: 0.9367, Test: 0.9382\n",
      "Epoch: 011, Loss: 0.4576, Val: 0.9372, Test: 0.9389\n",
      "Epoch: 012, Loss: 0.4578, Val: 0.9375, Test: 0.9395\n",
      "Epoch: 013, Loss: 0.4569, Val: 0.9380, Test: 0.9403\n",
      "Epoch: 014, Loss: 0.4563, Val: 0.9392, Test: 0.9417\n",
      "Epoch: 015, Loss: 0.4550, Val: 0.9399, Test: 0.9426\n",
      "Epoch: 016, Loss: 0.4534, Val: 0.9402, Test: 0.9431\n",
      "Epoch: 017, Loss: 0.4530, Val: 0.9410, Test: 0.9439\n",
      "Epoch: 018, Loss: 0.4513, Val: 0.9425, Test: 0.9454\n",
      "Epoch: 019, Loss: 0.4514, Val: 0.9425, Test: 0.9454\n",
      "Epoch: 020, Loss: 0.4490, Val: 0.9439, Test: 0.9470\n",
      "Epoch: 021, Loss: 0.4493, Val: 0.9443, Test: 0.9474\n",
      "Epoch: 022, Loss: 0.4481, Val: 0.9447, Test: 0.9478\n",
      "Epoch: 023, Loss: 0.4470, Val: 0.9463, Test: 0.9493\n",
      "Epoch: 024, Loss: 0.4464, Val: 0.9463, Test: 0.9493\n",
      "Epoch: 025, Loss: 0.4444, Val: 0.9470, Test: 0.9498\n",
      "Epoch: 026, Loss: 0.4458, Val: 0.9481, Test: 0.9509\n",
      "Epoch: 027, Loss: 0.4445, Val: 0.9481, Test: 0.9509\n",
      "Epoch: 028, Loss: 0.4444, Val: 0.9489, Test: 0.9518\n",
      "Epoch: 029, Loss: 0.4438, Val: 0.9507, Test: 0.9533\n"
     ]
    }
   ],
   "source": [
    "best_val_perf = test_perf = 0\n",
    "for epoch in range(1, 30):\n",
    "    train_loss = train()\n",
    "    val_perf, tmp_test_perf = test()\n",
    "    if val_perf > best_val_perf:\n",
    "        best_val_perf = val_perf\n",
    "        test_perf = tmp_test_perf\n",
    "    log = 'Epoch: {:03d}, Loss: {:.4f}, Val: {:.4f}, Test: {:.4f}'\n",
    "    print(log.format(epoch, train_loss, best_val_perf, test_perf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = model.encode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv(\"datasets/Test Dataset/test_edges.csv\")\n",
    "test_data = test_data.values.tolist()\n",
    "test_data_nodes_score = model.edgepred(z, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2.958502769470215,\n",
       " -0.3188187777996063,\n",
       " -0.2500545382499695,\n",
       " 2.3628921508789062,\n",
       " 0.08081190288066864]"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_score = [float(test_data_nodes_score[i][2]) for i in range(len(test_data))]\n",
    "test_data_score[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 0, 0, 1, 1]"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_prediction = [1 if score >0 else 0 for score in test_data_score]\n",
    "test_prediction[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([14497, 16895], dtype=int64)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommend_node, node_score = model.pred_one_edge(z, 1, top_k = 3)\n",
    "recommend_node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8.49590302, 8.32092667])"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_score"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5bf9334a660c555b7f15d06495026d4eebad3cd0e18f24e8e823e274a0e46bd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('pytorch': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
