{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\anaconda3\\envs\\pytorch\\lib\\site-packages\\gensim\\similarities\\__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from torch_geometric.utils import negative_sampling\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.utils import train_test_split_edges\n",
    "from torch_geometric.data import Data\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2vec_model = Doc2Vec.load(\"test_doc2vec.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91208\\AppData\\Local\\Temp/ipykernel_3424/1112440491.py:3: DeprecationWarning: Call to deprecated `docvecs` (The `docvecs` property has been renamed `dv`.).\n",
      "  for i in range(len(doc2vec_model.docvecs)):\n",
      "C:\\Users\\91208\\AppData\\Local\\Temp/ipykernel_3424/1112440491.py:4: DeprecationWarning: Call to deprecated `docvecs` (The `docvecs` property has been renamed `dv`.).\n",
      "  word_feature_array.append(doc2vec_model.docvecs[i])\n"
     ]
    }
   ],
   "source": [
    "word_feature_array = []\n",
    "\n",
    "for i in range(len(doc2vec_model.docvecs)):\n",
    "    word_feature_array.append(doc2vec_model.docvecs[i])\n",
    "\n",
    "word_feature_array = np.array(word_feature_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_type = pd.read_csv(\"./datasets/Training/node_classification.csv\")\n",
    "node_type_onehot = np.zeros([len(node_type), 4])\n",
    "for i in range(len(node_type)):\n",
    "    node_type_onehot[i][node_type.iloc[i][1]-1] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_feature_array = np.concatenate((word_feature_array, node_type_onehot), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge = pd.read_csv(\"./datasets/Training/training_graph.csv\")\n",
    "edge = edge.to_numpy().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = Data(x=torch.tensor(all_feature_array, dtype=torch.float32),\n",
    "    edge_index=torch.tensor(edge, dtype=torch.long), edge_attr=None)\n",
    "\n",
    "all_data.num_nodes = len(all_feature_array)\n",
    "all_data.num_features = len(all_feature_array[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch_geometric\\deprecation.py:13: UserWarning: 'train_test_split_edges' is deprecated, use 'transforms.RandomLinkSplit' instead\n",
      "  warnings.warn(out)\n"
     ]
    }
   ],
   "source": [
    "data = train_test_split_edges(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = GCNConv(data.num_features, 128)\n",
    "        self.conv2 = GCNConv(128, 64)\n",
    "\n",
    "    def encode(self):\n",
    "        x = self.conv1(data.x, data.train_pos_edge_index)\n",
    "        x = x.relu()\n",
    "        return self.conv2(x, data.train_pos_edge_index)\n",
    "\n",
    "    def decode(self, z, pos_edge_index, neg_edge_index):\n",
    "        edge_index = torch.cat([pos_edge_index, neg_edge_index], dim=-1)\n",
    "        logits = (z[edge_index[0]] * z[edge_index[1]]).sum(dim=-1)\n",
    "        return logits\n",
    "\n",
    "    def decode_all(self, z):\n",
    "        prob_adj = z @ z.t()\n",
    "        return (prob_adj > 0).nonzero(as_tuple=False).t()\n",
    "\n",
    "    def edgepred(self,z,te):\n",
    "        prob_adj = z @ z.t()\n",
    "        for k in range(len(te)):\n",
    "            probability = prob_adj[te[k][0]][te[k][1]]\n",
    "            probability = probability.detach().numpy()\n",
    "            te[k].append(probability)\n",
    "        \n",
    "        return te\n",
    "    \n",
    "    def pred_one_edge(self, z, new_node, top_k = 5, remove_negative = True):\n",
    "        prob_adj = z @ z.t()\n",
    "        rank_list = np.zeros(data.num_nodes)\n",
    "        for k in range(data.num_nodes):\n",
    "            if k == new_node:\n",
    "                rank_list[k] = -np.inf\n",
    "            else:\n",
    "                probability = prob_adj[new_node][k]\n",
    "                probability = probability.detach().numpy()\n",
    "                rank_list[k] = probability\n",
    "\n",
    "        index_list = rank_list.argsort()\n",
    "        top_k_index = index_list[-1:-top_k-2:-1]\n",
    "        top_k_score = rank_list[top_k_index]\n",
    "\n",
    "        if remove_negative:\n",
    "            for neg_point, inde in enumerate(top_k_score):\n",
    "                if inde < 0:\n",
    "                    break\n",
    "            top_k_index = top_k_index[:neg_point]\n",
    "            top_k_score = top_k_score[:neg_point]\n",
    "\n",
    "        return top_k_index, top_k_score\n",
    "\n",
    "\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = 'cpu'\n",
    "model, data = Net().to(device), data.to(device)\n",
    "model = model.float()\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=0.01)\n",
    "\n",
    "\n",
    "def get_link_labels(pos_edge_index, neg_edge_index):\n",
    "    E = pos_edge_index.size(1) + neg_edge_index.size(1)\n",
    "    link_labels = torch.zeros(E, dtype=torch.float, device=device)\n",
    "    link_labels[:pos_edge_index.size(1)] = 1.\n",
    "    return link_labels\n",
    "\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "    neg_edge_index = negative_sampling(\n",
    "        edge_index=data.train_pos_edge_index, num_nodes=data.num_nodes,\n",
    "        num_neg_samples=data.train_pos_edge_index.size(1),\n",
    "        force_undirected=True,\n",
    "    )\n",
    "    optimizer.zero_grad()\n",
    "    z = model.encode()\n",
    "    link_logits = model.decode(z, data.train_pos_edge_index, neg_edge_index)\n",
    "    link_labels = get_link_labels(data.train_pos_edge_index, neg_edge_index)\n",
    "    loss = F.binary_cross_entropy_with_logits(link_logits, link_labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def test():\n",
    "    model.eval()\n",
    "    perfs = []\n",
    "    for prefix in [\"val\", \"test\"]:\n",
    "        pos_edge_index = data[f'{prefix}_pos_edge_index']\n",
    "        neg_edge_index = data[f'{prefix}_neg_edge_index']\n",
    "        z = model.encode()\n",
    "        link_logits = model.decode(z, pos_edge_index, neg_edge_index)\n",
    "        link_probs = link_logits.sigmoid()\n",
    "        link_labels = get_link_labels(pos_edge_index, neg_edge_index)\n",
    "        perfs.append(roc_auc_score(link_labels.cpu(), link_probs.cpu()))\n",
    "    return perfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.6581, Val: 0.8933, Test: 0.8862\n",
      "Epoch: 002, Loss: 0.6086, Val: 0.9078, Test: 0.9045\n",
      "Epoch: 003, Loss: 0.5552, Val: 0.9078, Test: 0.9045\n",
      "Epoch: 004, Loss: 0.5366, Val: 0.9214, Test: 0.9166\n",
      "Epoch: 005, Loss: 0.5088, Val: 0.9214, Test: 0.9166\n",
      "Epoch: 006, Loss: 0.5036, Val: 0.9215, Test: 0.9161\n",
      "Epoch: 007, Loss: 0.4988, Val: 0.9215, Test: 0.9161\n",
      "Epoch: 008, Loss: 0.4973, Val: 0.9247, Test: 0.9190\n",
      "Epoch: 009, Loss: 0.4858, Val: 0.9262, Test: 0.9206\n",
      "Epoch: 010, Loss: 0.4836, Val: 0.9266, Test: 0.9211\n",
      "Epoch: 011, Loss: 0.4813, Val: 0.9268, Test: 0.9216\n",
      "Epoch: 012, Loss: 0.4838, Val: 0.9268, Test: 0.9216\n",
      "Epoch: 013, Loss: 0.4834, Val: 0.9270, Test: 0.9228\n",
      "Epoch: 014, Loss: 0.4828, Val: 0.9278, Test: 0.9240\n",
      "Epoch: 015, Loss: 0.4786, Val: 0.9281, Test: 0.9246\n",
      "Epoch: 016, Loss: 0.4778, Val: 0.9281, Test: 0.9246\n",
      "Epoch: 017, Loss: 0.4736, Val: 0.9281, Test: 0.9246\n",
      "Epoch: 018, Loss: 0.4733, Val: 0.9281, Test: 0.9246\n",
      "Epoch: 019, Loss: 0.4727, Val: 0.9283, Test: 0.9247\n",
      "Epoch: 020, Loss: 0.4728, Val: 0.9298, Test: 0.9261\n",
      "Epoch: 021, Loss: 0.4701, Val: 0.9313, Test: 0.9276\n",
      "Epoch: 022, Loss: 0.4715, Val: 0.9326, Test: 0.9291\n",
      "Epoch: 023, Loss: 0.4708, Val: 0.9340, Test: 0.9305\n",
      "Epoch: 024, Loss: 0.4664, Val: 0.9355, Test: 0.9319\n",
      "Epoch: 025, Loss: 0.4668, Val: 0.9365, Test: 0.9328\n",
      "Epoch: 026, Loss: 0.4649, Val: 0.9371, Test: 0.9332\n",
      "Epoch: 027, Loss: 0.4645, Val: 0.9374, Test: 0.9336\n",
      "Epoch: 028, Loss: 0.4638, Val: 0.9379, Test: 0.9341\n",
      "Epoch: 029, Loss: 0.4631, Val: 0.9390, Test: 0.9351\n"
     ]
    }
   ],
   "source": [
    "best_val_perf = test_perf = 0\n",
    "for epoch in range(1, 30):\n",
    "    train_loss = train()\n",
    "    val_perf, tmp_test_perf = test()\n",
    "    if val_perf > best_val_perf:\n",
    "        best_val_perf = val_perf\n",
    "        test_perf = tmp_test_perf\n",
    "    log = 'Epoch: {:03d}, Loss: {:.4f}, Val: {:.4f}, Test: {:.4f}'\n",
    "    print(log.format(epoch, train_loss, best_val_perf, test_perf))\n",
    "z = model.encode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv(\"datasets/Test Dataset/test_edges.csv\")\n",
    "test_data = test_data.values.tolist()\n",
    "test_data_nodes_score = model.edgepred(z, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2.8210692405700684,\n",
       " -0.6110092401504517,\n",
       " -0.27404236793518066,\n",
       " 2.379063844680786,\n",
       " -0.4723089635372162]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_score = [float(test_data_nodes_score[i][2]) for i in range(len(test_data))]\n",
    "test_data_score[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 0, 0, 1, 0]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_prediction = [1 if score >0 else 0 for score in test_data_score]\n",
    "test_prediction[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([14497, 16895, 21729, 19743], dtype=int64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommend_node, node_score = model.pred_one_edge(z, 1, top_k = 4)\n",
    "recommend_node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7.72844076, 7.41538095, 7.05592299, 6.84233332])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_score"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5bf9334a660c555b7f15d06495026d4eebad3cd0e18f24e8e823e274a0e46bd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('pytorch': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
